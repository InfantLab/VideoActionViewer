# Video Annotation Viewer v0.1.0

Advanced multimodal video annotation analysis tool for reviewing [VideoAnnotator](https://github.com/InfantLab/VideoAnnotator) pipeline outputs with synchronized pose detection, speech recognition, speaker diarization, and scene detection visualization.

## Overview

Video Annotation Viewer is a sophisticated web-based application designed for researchers and analysts working with multimodal video data. It provides an integrated interface for reviewing the outputs of automated video analysis pipelines, particularly those generated by the VideoAnnotator system.

## 🎯 Key Features

### 📹 **VideoAnnotator Integration**
- **Native Support**: Direct compatibility with VideoAnnotator pipeline outputs
- **Standard Formats**: COCO keypoints, WebVTT subtitles, RTTM speaker data, scene detection JSON
- **Multi-file Loading**: Drag-and-drop interface for video + annotation files
- **Automatic Detection**: Intelligent file type recognition and validation

### 🎥 **Multimodal Visualization**
- **Pose Detection**: COCO-format human pose keypoints with 17-point skeleton rendering
- **Speech Recognition**: WebVTT subtitle display with precise timing
- **Speaker Diarization**: RTTM-based speaker identification and timeline visualization  
- **Scene Detection**: Scene boundary markers and transition analysis
- **Track Persistence**: Person tracking with consistent identity across frames

### 📊 **Interactive Timeline**
- **Time-based Navigation**: Click-to-seek with millisecond precision
- **Multi-track Display**: Speech, speaker, scene, and motion tracks
- **Synchronized Playback**: All annotations stay perfectly aligned with video
- **Hover Details**: Rich information tooltips for timeline events

### 🎛️ **Professional Controls**
- **Overlay Management**: Toggle individual annotation layers on/off
- **Timeline Configuration**: Customize visible tracks and display options
- **Playback Controls**: Standard video controls plus frame stepping
- **Demo Mode**: Built-in sample data for immediate exploration

## 📁 Supported File Formats

### Video Files
- **MP4** (H.264/H.265)
- **WebM** 
- **AVI**
- **MOV**

### Annotation Files
- **Person Tracking**: COCO JSON format with keypoints and bounding boxes
- **Speech Recognition**: WebVTT (.vtt) files with timestamped transcriptions
- **Speaker Diarization**: RTTM (.rttm) files in NIST format
- **Scene Detection**: JSON arrays with scene boundaries and classifications
- **Audio**: Separate WAV files for audio analysis

## 🚀 Quick Start

### Demo Mode
1. Open the application
2. Click **"View Demo"** on the welcome screen
3. Explore the sample VideoAnnotator dataset with full multimodal annotations

### Load Your Own Data
1. Click **"Get Started"** from the welcome screen
2. Drag and drop your files:
   - One video file (e.g., `video.mp4`)
   - Multiple annotation files (e.g., `person_tracking.json`, `speech.vtt`, `speakers.rttm`, `scenes.json`)
3. The system automatically detects and validates file formats
4. Click **"Start Viewing"** to begin analysis

## 📊 Data Structure Examples

### COCO Person Tracking
```json
{
  "id": 1,
  "image_id": "frame_0001",
  "category_id": 1,
  "keypoints": [x1, y1, v1, x2, y2, v2, ...], // 17 keypoints × 3 values
  "bbox": [x, y, width, height],
  "track_id": 1,
  "timestamp": 1.25,
  "score": 0.95
}
```

### WebVTT Speech Recognition
```
WEBVTT

00:00:01.000 --> 00:00:03.500
Hello, how are you doing today?

00:00:04.000 --> 00:00:06.200
I'm doing great, thanks for asking.
```

### RTTM Speaker Diarization
```
SPEAKER filename 1 1.25 2.30 <NA> <NA> SPEAKER_00 <NA> <NA>
SPEAKER filename 1 3.80 1.50 <NA> <NA> SPEAKER_01 <NA> <NA>
```

### Scene Detection
```json
[
  {
    "id": 1,
    "start_time": 0.0,
    "end_time": 5.2,
    "scene_type": "conversation",
    "score": 0.89
  }
]
```

## 🔧 Development

### Prerequisites
- Node.js 18+ or Bun runtime
- Modern web browser with ES2020 support

### Local Development
```bash
# Clone the repository
git clone https://github.com/InfantLab/video-annotation-viewer.git
cd video-annotation-viewer

# Install dependencies
bun install
# or npm install

# Start development server
bun run dev
# or npm run dev

# Build for production
bun run build
# or npm run build
```

### Project Structure
```
src/
├── components/           # React components
│   ├── VideoPlayer.tsx   # Main video player with overlays
│   ├── Timeline.tsx      # Interactive timeline component
│   ├── FileUploader.tsx  # Multi-file upload interface
│   └── ...
├── lib/parsers/          # Format-specific parsers
│   ├── coco.ts          # COCO format parser
│   ├── webvtt.ts        # WebVTT parser
│   ├── rttm.ts          # RTTM parser
│   └── merger.ts        # Data integration utility
├── types/               # TypeScript type definitions
│   └── annotations.ts   # Standard format interfaces
└── utils/               # Utility functions
    ├── debugUtils.ts    # Demo data loading
    └── version.ts       # Version management
```

## 🎯 Use Cases

### Research Applications
- **Behavioral Analysis**: Review automated behavior detection results
- **Algorithm Validation**: Verify computer vision pipeline accuracy
- **Multimodal Studies**: Analyze speech, movement, and visual data together
- **Dataset Annotation**: Quality control for training data

### Clinical & Educational
- **Therapy Assessment**: Analyze patient-therapist interactions
- **Developmental Studies**: Track child development indicators
- **Social Interaction**: Study group dynamics and communication patterns
- **Movement Analysis**: Assess motor skills and physical therapy progress

## 🔗 Integration

Video Annotation Viewer is designed to work seamlessly with:
- **[VideoAnnotator](https://github.com/InfantLab/VideoAnnotator)**: Primary annotation pipeline
- **Research Workflows**: Export-ready data formats
- **Analysis Tools**: Standard format compatibility for further processing

## 📈 Version History

- **v0.1.0**: Initial release with full VideoAnnotator integration
  - COCO, WebVTT, RTTM, and Scene detection support
  - Multi-file upload and automatic format detection
  - Interactive timeline with synchronized playback
  - Demo dataset integration

## 🤝 Contributing

This project is part of the InfantLab research ecosystem. For contributions, issues, or feature requests:

1. Check the [GitHub repository](https://github.com/InfantLab/video-annotation-viewer)
2. Review existing issues and feature requests
3. Follow the project's coding standards and testing requirements

## 📄 License

See the LICENSE file for details.

---

**🏗️ Built with modern web technologies** | **⚡ Powered by Bun runtime** | **🔬 Made for researchers**
